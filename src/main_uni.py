# main_uni.py - VERS√ÉO PRODU√á√ÉO COM TREINAMENTO DESATIVADO

import warnings
import argparse
import sys
import os
import logging
import time
from pathlib import Path
from typing import Optional
import json

# ‚úÖ Silencia TUDO
os.environ["ORT_LOGGING_LEVEL"] = "3"
os.environ["ONNX_LOGGING_LEVEL"] = "3"
warnings.filterwarnings("ignore")

def force_delete_onnx(weights_path: str) -> None:
    """‚úÖ APAGA ONNX SEMPRE"""
    onnx_path = Path(weights_path).with_suffix(".onnx")
    if onnx_path.exists():
        print(f"üóëÔ∏è Apagando ONNX existente: {onnx_path.name}")
        onnx_path.unlink()

def find_config_file():
    """Encontra arquivo de configura√ß√£o dispon√≠vel"""
    possible_configs = [
        "config.json",
        "src/config.json", 
        Path.cwd() / "config.json",
        Path.cwd() / "src" / "config.json"
    ]
    
    for config_path in possible_configs:
        if Path(config_path).exists():
            print(f"‚úÖ Usando config: {config_path}")
            return str(config_path)
    
    print("‚ö†Ô∏è Config n√£o encontrado, criando config padr√£o...")
    return create_default_config()

def create_default_config(config_path="config.json"):
    """Cria configura√ß√£o padr√£o baseada no hardware"""
    
    # Detectar hardware dispon√≠vel
    try:
        import torch
        has_cuda = torch.cuda.is_available()
        if has_cuda:
            gpu_name = torch.cuda.get_device_name()
            print(f"üéÆ GPU detectada: {gpu_name}")
        else:
            print("üíª Usando CPU")
    except ImportError:
        has_cuda = False
        print("üíª PyTorch n√£o encontrado, assumindo CPU")
    
    try:
        import psutil
        cpu_cores = psutil.cpu_count(logical=False)
        optimal_threads = min(cpu_cores, 12)
    except ImportError:
        optimal_threads = 8
    
    # ‚úÖ USAR SEU CONFIG COMO BASE - FOCO EM PRODU√á√ÉO
    config = {
        "tracking": {
            "tracker": "bytetrack.yaml",
            "inference": {
                "device": "cpu",
                "half_precision": False
            },
            "detection": {
                "imgsz_cpu": 320,
                "conf_threshold": 0.45,
                "iou_threshold": 0.6,
                "max_det": 25
            },
            "classification_model": {
                "imgsz": 128,
                "batch_size": 10,
                "center_crop_margin": 0.15,
                "min_crop_size": 10
            },
            "classification": {
                "min_confidence": 0.35
            },
            "sampling": {
                "classify_every": 5
            },
            "performance": {
                "frame_stride": 2,
                "detection_interval": 3,
                "num_threads_cpu": optimal_threads,
                "use_onnx": False,
                "force_pytorch": True,
                "force_classification_pytorch": True,
                "enable_warmup": True,
                "warmup_iterations": 3
            },
            "visualization": {
                "draw_boxes": True,
                "draw_track_id": True,
                "draw_labels": True,
                "draw_confidence": True,
                "box_thickness": 2,
                "font_scale": 0.6,
                "font_thickness": 2
            },
            "output": {
                "save_video": True,
                "save_json": True,
                "save_csv": True,
                "video_codec": "mp4v",
                "timeline_mode": "duplicate"
            }
        },
        "api": {
            "server": {
                "host": "127.0.0.1",
                "port": 8000,
                "workers": 1,
                "reload": False,
                "debug": False
            },
            "upload": {
                "max_file_size": 500,
                "allowed_extensions": [".mp4", ".avi", ".mov", ".mkv"],
                "upload_dir": "uploads",
                "cleanup_after_hours": 24
            },
            "processing": {
                "queue_size": 10,
                "concurrent_jobs": 2,
                "timeout_minutes": 30
            },
            "security": {
                "rate_limit": 10,
                "rate_window_minutes": 1
            }
        },
        "system": {
            "production_mode": True,
            "training_disabled": True,
            "cicd_pipeline": "future_implementation"
        }
    }
    
    with open(config_path, 'w') as f:
        json.dump(config, f, indent=2)
    
    print(f"‚úÖ Config de produ√ß√£o criado: {config_path}")
    return config_path

def validate_config(config_path):
    """Valida se o config tem as se√ß√µes necess√°rias"""
    try:
        with open(config_path, 'r') as f:
            config = json.load(f)
        
        required_sections = ["tracking"]
        missing = [section for section in required_sections if section not in config]
        
        if missing:
            print(f"‚ö†Ô∏è Se√ß√µes ausentes no config: {missing}")
            return False
        
        print(f"‚úÖ Config v√°lido: {config_path}")
        return True
        
    except json.JSONDecodeError as e:
        print(f"‚ùå Config JSON inv√°lido: {e}")
        return False
    except Exception as e:
        print(f"‚ùå Erro lendo config: {e}")
        return False

def cmd_track_direct(video_path, det_weights, cls_weights, output_dir=""):
    """Tracking direto otimizado - PRODU√á√ÉO"""
    try:
        config_path = find_config_file()
        
        if not validate_config(config_path):
            print("‚ùå Config inv√°lido. Abortando...")
            return None
        
        # Limpeza ONNX
        print("üîÑ Limpando arquivos ONNX...")
        force_delete_onnx(det_weights)
        force_delete_onnx(cls_weights)
        
        # Valida√ß√£o de arquivos
        validations = [
            (video_path, "V√≠deo", "üìπ"),
            (det_weights, "Detector", "ü§ñ"),
            (cls_weights, "Classificador", "üé®")
        ]
        
        for file_path, name, icon in validations:
            if not Path(file_path).exists():
                print(f"‚ùå {name} n√£o encontrado: {file_path}")
                return None
            else:
                size_mb = Path(file_path).stat().st_size / (1024**2)
                print(f"‚úÖ {icon} {name}: {file_path} ({size_mb:.1f}MB)")
        
        print(f"‚öôÔ∏è Config: {config_path}")
        
        # Diagn√≥stico
        print("\nüîç === DIAGN√ìSTICO PRE-PROCESSAMENTO ===")
        
        try:
            import torch
            if torch.cuda.is_available():
                gpu_name = torch.cuda.get_device_name()
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
                print(f"üéÆ GPU: {gpu_name} ({gpu_memory:.1f}GB)")
            else:
                print("üíª Dispositivo: CPU")
                
            print(f"üî• PyTorch: {torch.__version__}")
        except ImportError:
            print("‚ö†Ô∏è PyTorch n√£o encontrado")
        
        try:
            import psutil
            cpu_count = psutil.cpu_count()
            cpu_freq = psutil.cpu_freq()
            ram_total = psutil.virtual_memory().total / (1024**3)
            print(f"üíª CPU: {cpu_count} cores @ {cpu_freq.current:.0f}MHz")
            print(f"üíæ RAM: {ram_total:.1f}GB")
        except ImportError:
            print("‚ö†Ô∏è psutil n√£o encontrado")
        
        try:
            from ultralytics import YOLO
            print("ü§ñ Ultralytics: ‚úÖ Dispon√≠vel")
        except ImportError:
            print("‚ùå Ultralytics n√£o encontrado! pip install ultralytics")
            return None
        
        # Executa tracking
        print("\nüöÄ Iniciando tracking otimizado...")
        from src.tracking.track import process_video_tracking
        
        start_total = time.time()
        
        result = process_video_tracking(
            video_path=video_path,
            det_weights=det_weights,
            cls_weights=cls_weights,
            config_path=config_path,
            out_dir=output_dir if output_dir else None,
        )
        
        total_time = time.time() - start_total
        
        if result:
            print(f"\nüéâ === TRACKING CONCLU√çDO ===")
            print(f"‚è±Ô∏è Tempo total: {total_time:.1f}s")
            print(f"üìä Tracks detectados: {result.get('total_tracks', 0)}")
            
            # Performance metrics
            if 'performance' in result:
                perf = result['performance']
                print(f"‚ö° FPS m√©dio: {perf.get('average_fps', 0):.1f}")
                print(f"üöÄ FPS equivalente: {perf.get('fps_raw_equiv', 0):.1f}")
            
            # Distribui√ß√£o de cores
            if 'color_distribution' in result and result['color_distribution']:
                print("üé® Distribui√ß√£o de cores:")
                total_vehicles = sum(result['color_distribution'].values())
                for color, count in result['color_distribution'].items():
                    percentage = (count / total_vehicles * 100) if total_vehicles > 0 else 0
                    print(f"   {color}: {count} ve√≠culos ({percentage:.1f}%)")
            
            # Arquivos gerados
            if 'output_files' in result and result['output_files']:
                print("üìÅ Arquivos gerados:")
                for file_type, file_path in result['output_files'].items():
                    if file_path and Path(file_path).exists():
                        size_mb = Path(file_path).stat().st_size / (1024**2)
                        print(f"   {file_type}: {Path(file_path).name} ({size_mb:.1f}MB)")
        else:
            print("\n‚ùå Processamento falhou.")
        
        return result
        
    except Exception as e:
        print(f"‚ùå Erro no tracking: {e}")
        import traceback
        traceback.print_exc()
        return None

def cmd_api_integrated(host="127.0.0.1", port=8000, reload=False):
    """‚úÖ API INTEGRADA COM MAIN_API.PY COMPLETA"""
    try:
        print("üöÄ === INICIANDO API INTEGRADA ===")
        
        # ‚úÖ VERIFICAR SE MAIN_API.PY EXISTE
        api_paths = [
            "src/api/main_api.py",
            "main_api.py",
            "src/main_api.py"
        ]
        
        api_file = None
        for api_path in api_paths:
            if Path(api_path).exists():
                api_file = api_path
                print(f"‚úÖ API encontrada: {api_path}")
                break
        
        if not api_file:
            print("‚ö†Ô∏è main_api.py n√£o encontrado, criando API b√°sica...")
            return cmd_api_basic(host, port)
        
        # ‚úÖ TENTAR IMPORTAR E EXECUTAR API COMPLETA
        try:
            import uvicorn
            print("‚úÖ Uvicorn dispon√≠vel")
            
            # Verificar depend√™ncias da API
            try:
                import fastapi
                from fastapi import FastAPI, UploadFile, File, HTTPException
                from fastapi.responses import JSONResponse, FileResponse
                print("‚úÖ FastAPI dispon√≠vel")
            except ImportError as e:
                print(f"‚ùå FastAPI n√£o dispon√≠vel: {e}")
                print("üí° Instale: pip install fastapi uvicorn python-multipart")
                return None
            
            # ‚úÖ IMPORTAR E EXECUTAR API COMPLETA
            if api_file == "src/api/main_api.py":
                from src.api.main_api import app
                print("‚úÖ API completa carregada de src/api/main_api.py")
            elif api_file == "main_api.py":
                from main_api import app
                print("‚úÖ API completa carregada de main_api.py")
            elif api_file == "src/main_api.py":
                from src.main_api import app
                print("‚úÖ API completa carregada de src/main_api.py")
            
            print(f"üåê Servidor: http://{host}:{port}")
            print(f"üìñ Documenta√ß√£o: http://{host}:{port}/docs")
            print(f"üîß Swagger UI: http://{host}:{port}/redoc")
            print("üí° Pressione Ctrl+C para parar")
            
            if reload:
                print("üîÑ Modo desenvolvimento (auto-reload)")
                if api_file == "src/api/main_api.py":
                    uvicorn.run("src.api.main_api:app", host=host, port=port, reload=True, workers=1)
                elif api_file == "main_api.py":
                    uvicorn.run("main_api:app", host=host, port=port, reload=True, workers=1)
                elif api_file == "src/main_api.py":
                    uvicorn.run("src.main_api:app", host=host, port=port, reload=True, workers=1)
            else:
                uvicorn.run(app, host=host, port=port, reload=False, workers=1)
            
            return {"success": True}
            
        except ImportError as e:
            print(f"‚ùå Erro importando API: {e}")
            print("üìã Falling back to basic API...")
            return cmd_api_basic(host, port)
            
    except KeyboardInterrupt:
        print("\nüëã API interrompida pelo usu√°rio")
        return {"success": True, "message": "Interrompido"}
    except Exception as e:
        print(f"‚ùå Erro na API integrada: {e}")
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}

def cmd_api_basic(host="127.0.0.1", port=8000):
    """API b√°sica como fallback"""
    try:
        import uvicorn
        from fastapi import FastAPI, UploadFile, File, HTTPException
        from fastapi.responses import JSONResponse
        from fastapi.middleware.cors import CORSMiddleware
        
        print("üîß Criando API b√°sica (fallback)...")
        
        app = FastAPI(
            title="Vox Color Detection API - Production",
            description="API de produ√ß√£o para detec√ß√£o e classifica√ß√£o de cores de ve√≠culos",
            version="2.0.0"
        )
        
        # CORS
        app.add_middleware(
            CORSMiddleware,
            allow_origins=["*"],
            allow_credentials=True,
            allow_methods=["*"],
            allow_headers=["*"],
        )
        
        @app.get("/")
        def root():
            return {
                "message": "Vox API - Production Mode",
                "status": "ok",
                "version": "2.0.0",
                "mode": "production",
                "training": "disabled"
            }
        
        @app.get("/health")
        def health():
            try:
                import torch
                cuda_available = torch.cuda.is_available()
                if cuda_available:
                    gpu_name = torch.cuda.get_device_name()
                    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
                    gpu_info = f"{gpu_name} ({gpu_memory:.1f}GB)"
                else:
                    gpu_info = "N/A"
            except:
                cuda_available = False
                gpu_info = "N/A"
            
            return {
                "status": "healthy",
                "mode": "production",
                "cuda_available": cuda_available,
                "gpu_info": gpu_info,
                "config_exists": Path("config.json").exists(),
                "tracking_available": Path("src/tracking/track.py").exists(),
                "training_disabled": True
            }
        
        @app.post("/upload")
        async def upload_video(file: UploadFile = File(...)):
            if not file.filename.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):
                raise HTTPException(status_code=400, detail="Formato de v√≠deo n√£o suportado")
            
            return {
                "message": "Upload recebido (API de produ√ß√£o)",
                "filename": file.filename,
                "size": file.size,
                "note": "Para processamento completo, use a API principal"
            }
        
        @app.post("/track")
        async def track_basic(file: UploadFile = File(...)):
            return {
                "message": "Endpoint b√°sico - use a API principal para processamento completo",
                "filename": file.filename,
                "status": "received"
            }
        
        print(f"üåê API de produ√ß√£o: http://{host}:{port}")
        print(f"üìñ Documenta√ß√£o: http://{host}:{port}/docs")
        print("üí° Pressione Ctrl+C para parar")
        
        uvicorn.run(app, host=host, port=port, log_level="info")
        
    except ImportError as e:
        print(f"‚ùå Depend√™ncias da API n√£o encontradas: {e}")
        print("üí° Instale: pip install fastapi uvicorn python-multipart")
    except Exception as e:
        print(f"‚ùå Erro na API b√°sica: {e}")

# üö´ ============================================================================
# TREINAMENTO DESATIVADO - IMPLEMENTA√á√ÉO FUTURA VIA CI/CD PIPELINE
# ============================================================================

def cmd_train_detect_disabled(config_path, variant="n"):
    """üö´ TREINAMENTO DE DETEC√á√ÉO - DESATIVADO"""
    print("\n" + "="*70)
    print("üö´ FUNCIONALIDADE DE TREINAMENTO TEMPORARIAMENTE DESATIVADA")
    print("="*70)
    print("üìã Status: Desabilitado para vers√£o de produ√ß√£o")
    print("üîÑ Implementa√ß√£o: Planejada para pipeline CI/CD")
    print("üéØ Objetivo: Automatiza√ß√£o via containers e cloud")
    print("üìÖ Previs√£o: Pr√≥xima vers√£o (v3.0)")
    print("")
    print("üí° PR√ìXIMOS PASSOS:")
    print("   1. Configura√ß√£o de ambiente de treinamento isolado")
    print("   2. Pipeline automatizado com MLflow")
    print("   3. Deployment autom√°tico de modelos")
    print("   4. Monitoramento de performance")
    print("   5. Versionamento autom√°tico de modelos")
    print("")
    print("üîß Para ativar temporariamente:")
    print("   - Modifique a flag 'training_disabled' no config")
    print("   - Ou implemente pipeline CI/CD personalizado")
    print("="*70)
    
    return {
        "success": False, 
        "status": "disabled",
        "message": "Treinamento desativado - implementa√ß√£o futura via CI/CD",
        "next_steps": [
            "Setup CI/CD pipeline",
            "Container training environment",
            "MLflow integration",
            "Automated model deployment"
        ]
    }

def cmd_train_classify_disabled(config_path, variant="n", data_path=""):
    """üö´ TREINAMENTO DE CLASSIFICA√á√ÉO - DESATIVADO"""
    print("\n" + "="*70)
    print("üö´ FUNCIONALIDADE DE TREINAMENTO TEMPORARIAMENTE DESATIVADA")
    print("="*70)
    print("üìã Status: Desabilitado para vers√£o de produ√ß√£o")
    print("üîÑ Implementa√ß√£o: Planejada para pipeline CI/CD")
    print("üéØ Objetivo: Automatiza√ß√£o via containers e cloud")
    print("üìÖ Previs√£o: Pr√≥xima vers√£o (v3.0)")
    print("")
    print("üí° BENEF√çCIOS DO PIPELINE CI/CD:")
    print("   ‚úÖ Treinamento automatizado em cloud")
    print("   ‚úÖ Versionamento autom√°tico de modelos")
    print("   ‚úÖ Testes automatizados de qualidade")
    print("   ‚úÖ Deploy sem interrup√ß√£o de servi√ßo")
    print("   ‚úÖ Rollback autom√°tico se performance cair")
    print("   ‚úÖ Monitoramento cont√≠nuo de drift")
    print("")
    print("üèóÔ∏è ARQUITETURA PLANEJADA:")
    print("   üê≥ Docker containers para treinamento")
    print("   ‚òÅÔ∏è Cloud GPU instances sob demanda")
    print("   üìä MLflow para tracking de experimentos")
    print("   üöÄ Kubernetes para orquestra√ß√£o")
    print("   üìà Prometheus para monitoramento")
    print("="*70)
    
    return {
        "success": False,
        "status": "disabled", 
        "message": "Treinamento desativado - implementa√ß√£o futura via CI/CD",
        "planned_features": [
            "Automated cloud training",
            "Model versioning",
            "Quality gates",
            "Zero-downtime deployment",
            "Performance monitoring"
        ]
    }

def prompt_choice(title, options):
    """Menu de escolha otimizado"""
    print(f"\n{title}")
    for i, opt in enumerate(options, 1):
        print(f" {i}) {opt}")
    
    while True:
        try:
            choice = input("Escolha [n√∫mero]: ").strip()
            if choice.isdigit() and 1 <= int(choice) <= len(options):
                return int(choice) - 1
        except (KeyboardInterrupt, EOFError):
            print("\nüëã Saindo...")
            sys.exit(0)
        except:
            pass
        print("‚ùå Inv√°lido. Tente novamente.")

def prompt_text(msg, default=None):
    """Prompt de texto otimizado"""
    prompt = f"{msg}"
    if default:
        prompt += f" [{default}]"
    prompt += ": "
    
    try:
        result = input(prompt).strip()
        return result if result else (default or "")
    except (KeyboardInterrupt, EOFError):
        print("\nüëã Saindo...")
        sys.exit(0)

def show_system_info():
    """Mostra informa√ß√µes completas do sistema"""
    print("\nüíª === INFORMA√á√ïES DO SISTEMA - MODO PRODU√á√ÉO ===")
    
    # Python
    print(f"üêç Python: {sys.version.split()[0]} ({sys.platform})")
    print(f"üìÇ Diret√≥rio atual: {Path.cwd()}")
    
    # PyTorch
    try:
        import torch
        print(f"üî• PyTorch: {torch.__version__}")
        print(f"üéÆ CUDA dispon√≠vel: {'Sim' if torch.cuda.is_available() else 'N√£o'}")
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name()
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
            print(f"üéÆ GPU: {gpu_name} ({gpu_memory:.1f}GB)")
    except ImportError:
        print("üî• PyTorch: ‚ùå N√£o instalado")
    
    # Ultralytics
    try:
        from ultralytics import YOLO
        import ultralytics
        print(f"ü§ñ Ultralytics: {ultralytics.__version__}")
    except ImportError:
        print("ü§ñ Ultralytics: ‚ùå N√£o instalado")
    
    # OpenCV
    try:
        import cv2
        print(f"üì∑ OpenCV: {cv2.__version__}")
    except ImportError:
        print("üì∑ OpenCV: ‚ùå N√£o instalado")
    
    # FastAPI
    try:
        import fastapi
        print(f"üöÄ FastAPI: {fastapi.__version__}")
    except ImportError:
        print("üöÄ FastAPI: ‚ùå N√£o instalado")
    
    # Sistema
    try:
        import psutil
        cpu_count = psutil.cpu_count()
        cpu_freq = psutil.cpu_freq()
        ram = psutil.virtual_memory()
        print(f"üíª CPU: {cpu_count} cores @ {cpu_freq.current:.0f}MHz")
        print(f"üíæ RAM: {ram.total/(1024**3):.1f}GB total")
    except ImportError:
        print("üíª System info: psutil n√£o dispon√≠vel")
    
    # Config e arquivos
    config_path = find_config_file()
    print(f"‚öôÔ∏è Config: {'‚úÖ' if Path(config_path).exists() else '‚ùå'} {config_path}")
    
    api_files = ["src/api/main_api.py", "main_api.py", "src/main_api.py"]
    api_found = any(Path(f).exists() for f in api_files)
    print(f"üöÄ API completa: {'‚úÖ' if api_found else '‚ùå'}")
    
    track_file = Path("src/tracking/track.py")
    print(f"üéØ Track module: {'‚úÖ' if track_file.exists() else '‚ùå'}")
    
    # Status de produ√ß√£o
    print(f"\nüè≠ === STATUS DE PRODU√á√ÉO ===")
    print(f"üîß Modo: Produ√ß√£o (Production Mode)")
    print(f"üö´ Treinamento: Desativado")
    print(f"üìà Tracking: Ativo")
    print(f"üåê API: Ativa")
    print(f"üîÑ CI/CD: Planejado para v3.0")

def interactive_main():
    """Interface interativa - MODO PRODU√á√ÉO"""
    print("\nüöó === Vox - MODO PRODU√á√ÉO ===")
    print("üè≠ Vers√£o de produ√ß√£o com foco em infer√™ncia")
    print("üö´ Treinamento desativado - Pipeline CI/CD em desenvolvimento")
    
    config_path = find_config_file()
    
    while True:
        choice = prompt_choice(
            "üéØ O que deseja fazer?",
            [
                "üé• Processar v√≠deo (Tracking + Classifica√ß√£o)",
                "üöÄ Iniciar API (Integrada com main_api.py)",
                "üö´ Treinar modelo de detec√ß√£o (DESATIVADO)",
                "üö´ Treinar modelo de classifica√ß√£o (DESATIVADO)",
                "‚ÑπÔ∏è Informa√ß√µes do sistema",
                "üß™ Testar depend√™ncias",
                "‚ùå Sair"
            ]
        )
        
        if choice == 0:  # Tracking
            print("\nüìπ === PROCESSAMENTO DE V√çDEO ===")
            
            video = prompt_text("Caminho do v√≠deo", "input.mp4")
            det_weights = prompt_text("Detector (.pt)", "runs/yolo11n_detection_detect3/weights/best.pt")
            cls_weights = prompt_text("Classificador (.pt)", "runs/yolo11n_classification_colors_n3/weights/best.pt")
            output_dir = prompt_text("Diret√≥rio de sa√≠da (opcional)", "")
            
            print(f"\nüîÑ Processando em modo produ√ß√£o...")
            result = cmd_track_direct(video, det_weights, cls_weights, output_dir)
            
            if result:
                input("\n‚úÖ Processamento conclu√≠do! Pressione Enter para continuar...")
            else:
                input("\n‚ùå Erro no processamento. Pressione Enter para continuar...")
        
        elif choice == 1:  # API Integrada
            print("\nüöÄ === API MODO PRODU√á√ÉO ===")
            
            host = prompt_text("Host", "127.0.0.1")
            port_str = prompt_text("Porta", "8000")
            reload_str = prompt_text("Auto-reload? (y/N)", "n")
            
            try:
                port = int(port_str)
                reload = reload_str.lower().startswith('y')
                
                print(f"\nüåê Iniciando API de produ√ß√£o em http://{host}:{port}")
                cmd_api_integrated(host, port, reload)
            except ValueError:
                print("‚ùå Porta inv√°lida")
                input("Pressione Enter para continuar...")
        
        elif choice == 2:  # Treinar detec√ß√£o - DESATIVADO
            print("\nüö´ === TREINAMENTO DE DETEC√á√ÉO - DESATIVADO ===")
            variant = prompt_text("Variante do modelo (n/s/m/l/x)", "n")
            cmd_train_detect_disabled(config_path, variant)
            input("\nPressione Enter para continuar...")
        
        elif choice == 3:  # Treinar classifica√ß√£o - DESATIVADO
            print("\nüö´ === TREINAMENTO DE CLASSIFICA√á√ÉO - DESATIVADO ===")
            variant = prompt_text("Variante do modelo (n/s/m/l/x)", "s")
            cmd_train_classify_disabled(config_path, variant)
            input("\nPressione Enter para continuar...")
        
        elif choice == 4:  # Info do sistema
            show_system_info()
            input("\nPressione Enter para continuar...")
        
        elif choice == 5:  # Teste de depend√™ncias
            print("\nüß™ === TESTANDO DEPEND√äNCIAS - MODO PRODU√á√ÉO ===")
            
            # Depend√™ncias essenciais para produ√ß√£o
            production_dependencies = [
                ("torch", "PyTorch"),
                ("ultralytics", "Ultralytics YOLO"),
                ("cv2", "OpenCV"),
                ("PIL", "Pillow"),
                ("fastapi", "FastAPI"),
                ("uvicorn", "Uvicorn"),
                ("psutil", "psutil")
            ]
            
            all_ok = True
            for module_name, display_name in production_dependencies:
                try:
                    __import__(module_name)
                    print(f"‚úÖ {display_name}: OK")
                except ImportError:
                    print(f"‚ùå {display_name}: FALTANDO")
                    all_ok = False
            
            print("\nüîç Depend√™ncias opcionais para treinamento:")
            training_dependencies = [
                ("mlflow", "MLflow (CI/CD)"),
                ("wandb", "Weights & Biases (CI/CD)"),
                ("tensorboard", "TensorBoard (CI/CD)")
            ]
            
            for module_name, display_name in training_dependencies:
                try:
                    __import__(module_name)
                    print(f"üîÑ {display_name}: Dispon√≠vel (n√£o usado em produ√ß√£o)")
                except ImportError:
                    print(f"üö´ {display_name}: N√£o instalado (ser√° usado em CI/CD)")
            
            if all_ok:
                print("\nüéâ Todas as depend√™ncias de produ√ß√£o est√£o instaladas!")
                print("üè≠ Sistema pronto para uso em produ√ß√£o!")
            else:
                print("\n‚ö†Ô∏è Instale depend√™ncias de produ√ß√£o:")
                print("pip install torch ultralytics opencv-python pillow fastapi uvicorn psutil python-multipart")
            
            input("\nPressione Enter para continuar...")
        
        else:  # Sair
            print("\nüëã Saindo do modo produ√ß√£o... At√© mais!")
            break

def build_parser():
    """Parser com comandos de produ√ß√£o"""
    parser = argparse.ArgumentParser(
        description="Vox - Sistema de Produ√ß√£o v2.0",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
üè≠ MODO PRODU√á√ÉO - Exemplos de uso:
  python main_uni.py                                    # Modo interativo
  python main_uni.py track --video input.mp4 --det-weights detector.pt --cls-weights classifier.pt
  python main_uni.py api --host 0.0.0.0 --port 8000
  
üö´ TREINAMENTO DESATIVADO:
  - Funcionalidades de treinamento est√£o desabilitadas
  - Implementa√ß√£o planejada via pipeline CI/CD
  - Para desenvolvimento, use vers√£o separada

üí° Para ativar treinamento:
  - Configure pipeline CI/CD personalizado
  - Ou modifique flags no config.json
        """
    )
    
    subparsers = parser.add_subparsers(dest="command", required=False)
    
    # Track command (ATIVO)
    track_parser = subparsers.add_parser("track", help="Processar v√≠deo (PRODU√á√ÉO)")
    track_parser.add_argument("--video", required=True, help="Caminho do v√≠deo")
    track_parser.add_argument("--det-weights", required=True, help="Pesos do detector (.pt)")
    track_parser.add_argument("--cls-weights", required=True, help="Pesos do classificador (.pt)")
    track_parser.add_argument("--output", default="", help="Diret√≥rio de sa√≠da")
    
    # API command (ATIVO)
    api_parser = subparsers.add_parser("api", help="Iniciar API (PRODU√á√ÉO)")
    api_parser.add_argument("--host", default="127.0.0.1", help="Host da API")
    api_parser.add_argument("--port", type=int, default=8000, help="Porta da API")
    api_parser.add_argument("--reload", action="store_true", help="Auto-reload")
    
    # Train commands (DESATIVADOS)
    train_detect_parser = subparsers.add_parser("train-detect", help="Treinar detec√ß√£o (DESATIVADO)")
    train_detect_parser.add_argument("--variant", default="n", choices=['n', 's', 'm', 'l', 'x'], help="Variante do modelo")
    
    train_classify_parser = subparsers.add_parser("train-classify", help="Treinar classifica√ß√£o (DESATIVADO)")
    train_classify_parser.add_argument("--variant", default="s", choices=['n', 's', 'm', 'l', 'x'], help="Variante do modelo")
    
    # Other commands
    subparsers.add_parser("interactive", help="Modo interativo (PRODU√á√ÉO)")
    subparsers.add_parser("info", help="Informa√ß√µes do sistema")
    
    return parser

def main():
    """Fun√ß√£o principal - MODO PRODU√á√ÉO"""
    print("üè≠ Vox - MODO PRODU√á√ÉO")
    print("üö´ Treinamento desativado | üéØ Foco em infer√™ncia")
    
    parser = build_parser()
    args = parser.parse_args()
    
    # Se nenhum comando, inicia interativo
    if args.command is None:
        print("‚ÑπÔ∏è Iniciando modo interativo de produ√ß√£o...")
        interactive_main()
        return
    
    # Comandos CLI
    config_path = find_config_file()
    
    if args.command == "track":
        result = cmd_track_direct(args.video, args.det_weights, args.cls_weights, args.output)
        return result
    
    elif args.command == "api":
        cmd_api_integrated(args.host, args.port, args.reload)
        return
    
    elif args.command == "train-detect":
        result = cmd_train_detect_disabled(config_path, args.variant)
        return result
    
    elif args.command == "train-classify":
        result = cmd_train_classify_disabled(config_path, args.variant)
        return result
    
    elif args.command == "interactive":
        interactive_main()
        return
    
    elif args.command == "info":
        show_system_info()
        return
    
    else:
        print(f"‚ùå Comando desconhecido: {args.command}")
        parser.print_help()

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nüëã Interrompido pelo usu√°rio!")
    except Exception as e:
        print(f"\n‚ùå Erro inesperado: {e}")
        import traceback
        traceback.print_exc()