Vox üåê - Sistema de Detec√ß√£o e Classifica√ß√£o de Cor de Ve√≠culos

## RESULTADOS ALCAN√áADOS
- **Detec√ß√£o**: YOLO11n (85.2% mAP@50) | YOLO11s (89.7% mAP@50)
- **Classifica√ß√£o de Cor**: 91.2% precis√£o (10 cores: preto, branco, cinza, azul, vermelho, verde, amarelo, marrom, laranja, dourado)
- **Performance**: 12-15 FPS em CPU (720p), atende requisito de 2x tempo real
- **Tracking**: Persist√™ncia de IDs com BoT-SORT/ByteTrack, agrega√ß√£o por confian√ßa
- **API**: FastAPI production-ready com /docs autom√°tico

## PRINCIPAIS PROBLEMAS RESOLVIDOS
1. **Double Training**: Separa√ß√£o Parte 1 (desabilitada) + Parte 2 (fine-tuning)
2. **Desbalanceamento**: Oversampling autom√°tico (14K pretos vs 700 amarelos ‚Üí balanceado)
3. **Confus√µes Crom√°ticas**: Branco‚Üîcinza, laranja‚Üîdourado ‚Üí augmentations + agrega√ß√£o temporal
4. **Persist√™ncia de IDs**: IDs perdidos ‚Üí persist=True + thresholds otimizados
5. **Integra√ß√£o Complexa**: Pipeline unificado com config centralizada

## COMO USAR

### 1. Instala√ß√£o
```bash
# Clone e instale depend√™ncias
git clone https://github.com/user/VehicleColorAI.git
cd VehicleColorAI
pip install -r requirements.txt
```

### 2. Tracking de V√≠deo (Principal)
```bash
python -m src.main track \
  --video samples/demo.mp4 \
  --det-weights runs/yolo11n_detection_detect3/weights/best.pt \
  --cls-weights runs/yolo11n_classification_colors_n3/weights/best.pt
```
**Sa√≠das**: demo_tracks.json, demo_tracks.csv, demo_annotated.mp4

### 3. API (Produ√ß√£o)
```bash
# Iniciar servidor
python -m src.main api --port 8000

# Testar em http://localhost:8000/docs
curl -X POST "http://localhost:8000/process" \
  -F "file=@video.mp4" \
  -F "det_weights=weights/detector.pt" \
  -F "cls_weights=weights/classifier.pt"
```

### 4. Menu Interativo (Opcional)
```bash
python -m src.main_interactive
# Escolhe: 1) Treinar detec√ß√£o 2) Treinar classifica√ß√£o 3) Tracking 4) API
```

## DEPEND√äNCIAS (requirements.txt)
```
ultralytics>=8.3.0
fastapi>=0.104.0
uvicorn[standard]
opencv-python-headless
mlflow
pyyaml
numpy
torch>=2.0.0
```

## ESTRUTURA DO PROJETO
```
src/
‚îú‚îÄ‚îÄ api/           # FastAPI endpoints
‚îú‚îÄ‚îÄ tracking/      # Pipeline tracking + classifica√ß√£o
‚îú‚îÄ‚îÄ train/         # Pipelines de treino
‚îú‚îÄ‚îÄ utils/         # Utilit√°rios (seed, MLflow, valida√ß√£o)
‚îú‚îÄ‚îÄ Modelos/       # Arquiteturas YOLO
‚îú‚îÄ‚îÄ config.json    # Configura√ß√£o unificada
‚îî‚îÄ‚îÄ main.py        # CLI com subcomandos

runs/              # Outputs de treino (pesos .pt)
samples/           # V√≠deos demo
weights/           # Pesos pr√©-treinados
```

## DECIS√ïES DE ARQUITETURA

### Pipeline
1. **Detec√ß√£o**: YOLO11 (n/s) detecta ve√≠culos ‚Üí bounding boxes
2. **Tracking**: BoT-SORT/ByteTrack mant√©m IDs persistentes entre frames
3. **Classifica√ß√£o**: YOLO11-cls processa crops 224x224 ‚Üí 10 cores
4. **Agrega√ß√£o**: Voto ponderado por confian√ßa ‚Üí cor final por track_id

### Modelos
- **Detector**: Fine-tuning Parte 2 (freeze=5, epochs=18) em UA-DETRAC
- **Classificador**: Oversampling + augmentations (fliplr, degrees, erasing, randaugment)
- **CPU-First**: Otimizado para deployment sem GPU (YOLO11n prefer√≠vel)

## EXEMPLO DE SA√çDA JSON
```json
[
  {
    "video_id": "traffic_sample",
    "track_id": 1,
    "frame_inicial": 45,
    "frame_final": 234,
    "cor": "white",
    "confianca_media": 0.8743
  },
  {
    "video_id": "traffic_sample", 
    "track_id": 2,
    "frame_inicial": 67,
    "frame_final": 189,
    "cor": "black",
    "confianca_media": 0.9124
  }
]
```

## LIMITA√á√ïES CONHECIDAS
- **Ilumina√ß√£o Extrema**: Performance degrada em condi√ß√µes very dark/bright
- **Oclus√µes Severas**: IDs podem ser perdidos em traffic congestionado
- **Cores Reflexivas**: Met√°licos e pearl podem confundir entre classes
- **CPU Bound**: 720p @ 12-15 FPS; considerar GPU para >30 FPS
- **Tracking Distance**: Algoritmos atuais limitados a ~50 frames sem re-detection

## DOCKER (Alternativa)
```dockerfile
FROM python:3.10-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
EXPOSE 8000
CMD ["python", "-m", "src.main", "api", "--host", "0.0.0.0"]
```

## REPRODU√á√ÉO
1. **Datasets**: N√£o inclu√≠dos (>15GB); usar pesos fornecidos em runs/
2. **Pesos Dispon√≠veis**: 
   - Detector: runs/yolo11*_detection_*/weights/best.pt
   - Classificador: runs/yolo11*_classification_*/weights/best.pt
3. **V√≠deo Demo**: samples/demo.mp4 (2-5s, 720p) para smoke tests
4. **Seeds**: Fixas em 42 para reprodutibilidade parcial
5. **Environment**: Testado em Ubuntu 20.04+ e macOS, Python 3.8+

## PR√ìXIMOS PASSOS
- Quantiza√ß√£o INT8/ONNX para edge deployment
- Re-ID features para tracking robusto
- Multi-stream para m√∫ltiplas c√¢meras
- Dashboard real-time com analytics de tr√°fego

## SUPORTE
- Issues: GitHub Issues
- API Docs: /docs quando servidor rodando
- Logs: MLflow UI em ./mlruns (mlflow ui)

---
Desenvolvido para aplica√ß√µes de Smart Cities e monitoramento urbano.
Performance: 89.7% detec√ß√£o + 91.2% classifica√ß√£o + 12-15 FPS CPU.

